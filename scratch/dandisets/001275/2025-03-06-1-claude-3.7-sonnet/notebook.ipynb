{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf84f1a",
   "metadata": {},
   "source": [
    "# Exploring Dandiset 001275: Mental Navigation in Primate PPC\n",
    "\n",
    "**IMPORTANT NOTICE**: This notebook was AI-generated with human supervision and has not been fully verified. Please be cautious when interpreting the code or results.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook explores [DANDI:001275](https://neurosift.app/dandiset/001275), a dataset containing neurophysiology data collected from two primates during a mental navigation task. The study is associated with a published paper: https://doi.org/10.1038/s41586-024-07557-z\n",
    "\n",
    "In this task, macaques navigate mentally between landmarks using a joystick without visual feedback. The dataset includes:\n",
    "\n",
    "- Neural recordings from the posterior parietal cortex (PPC)\n",
    "- Behavioral data (eye tracking, joystick movements)\n",
    "- Trial information\n",
    "\n",
    "A related dataset from the entorhinal cortex is available at: https://doi.org/10.48324/dandi/000897/0.240605.1710"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f42dcf",
   "metadata": {},
   "source": [
    "## Setup and Data Loading\n",
    "\n",
    "First, let's import the necessary libraries and load a sample NWB file from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3bd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pynwb\n",
    "import lindi\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f59803e",
   "metadata": {},
   "source": [
    "For this demonstration, we'll use a behavior+ecephys file from subject \"amadeus\". These files are smaller (hundreds of MB) and contain both behavioral and neural data, making them ideal for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508feb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a behavior+ecephys file (smaller file with both behavioral and neural data)\n",
    "print(\"Loading NWB file...\")\n",
    "f = lindi.LindiH5pyFile.from_lindi_file(\n",
    "    \"https://lindi.neurosift.org/dandi/dandisets/001275/assets/b0bbeb4c-5e0d-4050-a993-798173797d94/nwb.lindi.json\"\n",
    ")\n",
    "nwb = pynwb.NWBHDF5IO(file=f, mode='r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5464fde",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "Let's examine the basic information about this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd1cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print basic session information\n",
    "print(f\"Subject: {nwb.subject.subject_id} ({nwb.subject.species})\")\n",
    "print(f\"Sex: {nwb.subject.sex}, Age: {nwb.subject.age}\")\n",
    "print(f\"Session date: {nwb.session_start_time}\")\n",
    "print(f\"Lab: {nwb.lab}, Institution: {nwb.institution}\")\n",
    "print(f\"Session description: {nwb.session_description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17835463",
   "metadata": {},
   "source": [
    "## Task Description\n",
    "\n",
    "In this mental navigation task:\n",
    "\n",
    "1. The subject (macaque) is presented with a start and a target landmark from a linear map of 6 landmarks.\n",
    "2. After a delay, the subject is cued with a go signal to navigate from start to target landmark using a joystick.\n",
    "3. The subject responds by deflecting the joystick in the right direction and holding it until they think they've arrived at the target landmark.\n",
    "4. Importantly, the visual drift and intervening landmarks are occluded from view, making this a purely mental navigation task.\n",
    "\n",
    "Let's explore the trial structure to better understand the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ab1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trial information\n",
    "trials = nwb.intervals[\"trials\"]\n",
    "print(f\"Number of trials: {len(trials['start_time'].data)}\")\n",
    "print(f\"Trial columns: {trials.colnames}\")\n",
    "\n",
    "# Check for NaN values in start_time and stop_time\n",
    "start_times = trials[\"start_time\"].data[:]\n",
    "stop_times = trials[\"stop_time\"].data[:]\n",
    "valid_indices = ~(np.isnan(start_times) | np.isnan(stop_times))\n",
    "print(f\"Valid trials: {np.sum(valid_indices)} out of {len(start_times)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2249c2",
   "metadata": {},
   "source": [
    "## Trial Structure Analysis\n",
    "\n",
    "Let's analyze the trial structure in more detail, focusing on the navigation distances and success rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9189f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trial properties\n",
    "if 'target' in trials.colnames and 'curr' in trials.colnames:\n",
    "    # Load all data first, then apply boolean indexing\n",
    "    targets = trials['target'].data[:]\n",
    "    currents = trials['curr'].data[:]\n",
    "    \n",
    "    # Calculate distances\n",
    "    valid_indices = ~(np.isnan(targets) | np.isnan(currents))\n",
    "    valid_targets = targets[valid_indices]\n",
    "    valid_currents = currents[valid_indices]\n",
    "    distances = np.abs(valid_targets - valid_currents)\n",
    "    \n",
    "    print(f\"Navigation distances range from {np.min(distances):.0f} to {np.max(distances):.0f} landmarks\")\n",
    "    print(f\"Average distance: {np.mean(distances):.2f} landmarks\")\n",
    "    \n",
    "    # Create a DataFrame for easier analysis\n",
    "    trial_df = pd.DataFrame({\n",
    "        'start': valid_currents,\n",
    "        'target': valid_targets,\n",
    "        'distance': distances\n",
    "    })\n",
    "    \n",
    "    # Add success information if available\n",
    "    if 'succ' in trials.colnames:\n",
    "        # Load all success data first, then apply boolean indexing\n",
    "        all_success = trials['succ'].data[:]\n",
    "        success = all_success[valid_indices]\n",
    "        trial_df['success'] = success\n",
    "        print(f\"Overall success rate: {np.mean(success) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of navigation distances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x=trial_df['distance'], palette='viridis')\n",
    "plt.title('Distribution of Navigation Distances', fontsize=16)\n",
    "plt.xlabel('Distance (landmarks)', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(range(1, 6))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f79242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot success rate by distance\n",
    "if 'success' in trial_df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    success_by_dist = trial_df.groupby('distance')['success'].mean() * 100\n",
    "    \n",
    "    # Plot as bar chart\n",
    "    ax = success_by_dist.plot(kind='bar', color='teal', alpha=0.7)\n",
    "    plt.title('Success Rate by Navigation Distance', fontsize=16)\n",
    "    plt.xlabel('Distance (landmarks)', fontsize=14)\n",
    "    plt.ylabel('Success Rate (%)', fontsize=14)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text labels on bars\n",
    "    for i, v in enumerate(success_by_dist):\n",
    "        ax.text(i, v + 3, f\"{v:.1f}%\", ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a7efd6",
   "metadata": {},
   "source": [
    "The plots above reveal an important aspect of the task: **success rate decreases as navigation distance increases**. This makes intuitive sense - it's harder to mentally navigate longer distances accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e510c21",
   "metadata": {},
   "source": [
    "## Behavioral Data Analysis\n",
    "\n",
    "The dataset includes behavioral data such as eye position and hand position (joystick). Let's examine this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6d9bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get behavioral data interfaces\n",
    "behavior = nwb.processing[\"behavior\"]\n",
    "print(f\"Behavioral data types: {list(behavior.data_interfaces.keys())}\")\n",
    "\n",
    "# Get basic info about eye and hand position data\n",
    "eye_position = behavior[\"eye_position\"]\n",
    "hand_position = behavior[\"hand_position\"]\n",
    "\n",
    "print(f\"Eye position data shape: {eye_position.data.shape}\")\n",
    "print(f\"Hand position data shape: {hand_position.data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a079c86f",
   "metadata": {},
   "source": [
    "Let's look at a small sample of joystick movement data to understand the behavioral responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca31b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a small sample of hand position data (joystick movement)\n",
    "# We'll only load a small subset to avoid memory issues\n",
    "sample_start = 1000000  # Start at 1M sample to skip initial period\n",
    "sample_length = 10000   # Look at 10K samples\n",
    "\n",
    "# Load only the data we need\n",
    "hand_times = hand_position.timestamps[sample_start:sample_start+sample_length]\n",
    "hand_data = hand_position.data[sample_start:sample_start+sample_length]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(hand_times - hand_times[0], hand_data)\n",
    "plt.title('Sample Joystick Movement', fontsize=16)\n",
    "plt.xlabel('Time (seconds)', fontsize=14)\n",
    "plt.ylabel('Position', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c7905",
   "metadata": {},
   "source": [
    "## Neural Data Analysis\n",
    "\n",
    "Now let's explore the neural recordings from the posterior parietal cortex (PPC):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a822004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neural data\n",
    "units = nwb.processing[\"ecephys\"][\"units\"]\n",
    "print(f\"Number of units (neurons): {len(units['id'].data)}\")\n",
    "\n",
    "# Get quality counts\n",
    "quality_counts = {}\n",
    "for q in units[\"quality\"].data[:]:\n",
    "    if q in quality_counts:\n",
    "        quality_counts[q] += 1\n",
    "    else:\n",
    "        quality_counts[q] = 1\n",
    "\n",
    "print(f\"Unit quality counts: {quality_counts}\")\n",
    "\n",
    "# Filter for good units only\n",
    "good_unit_indices = [i for i, q in enumerate(units[\"quality\"].data[:]) if q == 'good']\n",
    "print(f\"Number of good units: {len(good_unit_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get firing rates of good units\n",
    "good_firing_rates = units[\"fr\"].data[:][good_unit_indices]\n",
    "print(f\"Average firing rate of good units: {np.mean(good_firing_rates):.2f} Hz\")\n",
    "print(f\"Min firing rate: {np.min(good_firing_rates):.2f} Hz\")\n",
    "print(f\"Max firing rate: {np.max(good_firing_rates):.2f} Hz\")\n",
    "\n",
    "# Plot distribution of firing rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(good_firing_rates, bins=15, kde=True, color='purple')\n",
    "plt.title('Distribution of Firing Rates (Good Units)', fontsize=16)\n",
    "plt.xlabel('Firing Rate (Hz)', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308365d0",
   "metadata": {},
   "source": [
    "## Neural Activity During Navigation\n",
    "\n",
    "Let's analyze how neural activity relates to the navigation task. We'll select a few example trials with different navigation distances and examine the neural responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87723996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find trial indices for each distance\n",
    "distance_trial_indices = {}\n",
    "for dist in range(1, 6):  # Distances 1 through 5\n",
    "    dist_indices = np.where((distances == dist) & valid_indices)[0]\n",
    "    if len(dist_indices) > 0:\n",
    "        # Take the first trial for each distance\n",
    "        distance_trial_indices[dist] = dist_indices[0]\n",
    "\n",
    "print(\"Example trials for neural analysis:\")\n",
    "for dist, trial_idx in distance_trial_indices.items():\n",
    "    print(f\"Distance {dist}: Trial {trial_idx}, Start={currents[trial_idx]:.0f}, Target={targets[trial_idx]:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ae761",
   "metadata": {},
   "source": [
    "Now let's analyze neural activity during these example trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6cfea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of good units for analysis (first 5)\n",
    "analysis_unit_indices = good_unit_indices[:5] if len(good_unit_indices) >= 5 else good_unit_indices\n",
    "print(f\"Analyzing {len(analysis_unit_indices)} good units\")\n",
    "\n",
    "# For each selected trial, count spikes from each unit during the trial\n",
    "trial_unit_spikes = {}\n",
    "\n",
    "for dist, trial_idx in distance_trial_indices.items():\n",
    "    trial_start = start_times[trial_idx]\n",
    "    trial_stop = stop_times[trial_idx]\n",
    "    trial_duration = trial_stop - trial_start\n",
    "    \n",
    "    unit_spikes = {}\n",
    "    for unit_idx in analysis_unit_indices:\n",
    "        # Get spike times for this unit\n",
    "        spike_times = units[\"spike_times\"][unit_idx]\n",
    "        \n",
    "        # Count spikes during this trial\n",
    "        trial_spikes = spike_times[(spike_times >= trial_start) & (spike_times <= trial_stop)]\n",
    "        spike_count = len(trial_spikes)\n",
    "        \n",
    "        # Calculate firing rate during this trial\n",
    "        trial_firing_rate = spike_count / trial_duration if trial_duration > 0 else 0\n",
    "        \n",
    "        unit_spikes[unit_idx] = {\n",
    "            'count': spike_count,\n",
    "            'rate': trial_firing_rate\n",
    "        }\n",
    "    \n",
    "    trial_unit_spikes[dist] = unit_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for visualization\n",
    "firing_rate_data = []\n",
    "for dist, unit_data in trial_unit_spikes.items():\n",
    "    for unit_idx, spike_data in unit_data.items():\n",
    "        unit_name = units[\"unit_name\"].data[unit_idx]\n",
    "        firing_rate_data.append({\n",
    "            'Distance': dist,\n",
    "            'Unit': f\"Unit {unit_name}\",\n",
    "            'Firing Rate (Hz)': spike_data['rate']\n",
    "        })\n",
    "\n",
    "firing_rate_df = pd.DataFrame(firing_rate_data)\n",
    "\n",
    "# Plot firing rates by distance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=firing_rate_df, x='Distance', y='Firing Rate (Hz)', \n",
    "             hue='Unit', marker='o', markersize=10, linewidth=2)\n",
    "plt.title('Firing Rates by Navigation Distance', fontsize=16)\n",
    "plt.xlabel('Distance (landmarks)', fontsize=14)\n",
    "plt.ylabel('Firing Rate (Hz)', fontsize=14)\n",
    "plt.xticks(range(1, 6))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15733b6f",
   "metadata": {},
   "source": [
    "## Neural Activity by Trial Outcome\n",
    "\n",
    "Let's compare neural activity during successful versus failed trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77baa23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'success' in trial_df.columns:\n",
    "    # Load all success data first\n",
    "    all_success = trials['succ'].data[:]\n",
    "    # Find successful and failed trials\n",
    "    successful_trials = np.where(all_success == 1)[0]\n",
    "    failed_trials = np.where(all_success == 0)[0]\n",
    "    \n",
    "    print(f\"Number of successful trials: {len(successful_trials)}\")\n",
    "    print(f\"Number of failed trials: {len(failed_trials)}\")\n",
    "    \n",
    "    # Select a subset of trials for analysis\n",
    "    num_trials_to_analyze = 10\n",
    "    successful_sample = successful_trials[:num_trials_to_analyze] if len(successful_trials) >= num_trials_to_analyze else successful_trials\n",
    "    failed_sample = failed_trials[:num_trials_to_analyze] if len(failed_trials) >= num_trials_to_analyze else failed_trials\n",
    "    \n",
    "    # Calculate average firing rates during successful and failed trials\n",
    "    success_rates = defaultdict(list)\n",
    "    failure_rates = defaultdict(list)\n",
    "    \n",
    "    # Process successful trials\n",
    "    for trial_idx in successful_sample:\n",
    "        if not valid_indices[trial_idx]:\n",
    "            continue\n",
    "            \n",
    "        trial_start = start_times[trial_idx]\n",
    "        trial_stop = stop_times[trial_idx]\n",
    "        trial_duration = trial_stop - trial_start\n",
    "        \n",
    "        for unit_idx in analysis_unit_indices:\n",
    "            spike_times = units[\"spike_times\"][unit_idx]\n",
    "            trial_spikes = spike_times[(spike_times >= trial_start) & (spike_times <= trial_stop)]\n",
    "            trial_firing_rate = len(trial_spikes) / trial_duration if trial_duration > 0 else 0\n",
    "            success_rates[unit_idx].append(trial_firing_rate)\n",
    "    \n",
    "    # Process failed trials\n",
    "    for trial_idx in failed_sample:\n",
    "        if not valid_indices[trial_idx]:\n",
    "            continue\n",
    "            \n",
    "        trial_start = start_times[trial_idx]\n",
    "        trial_stop = stop_times[trial_idx]\n",
    "        trial_duration = trial_stop - trial_start\n",
    "        \n",
    "        for unit_idx in analysis_unit_indices:\n",
    "            spike_times = units[\"spike_times\"][unit_idx]\n",
    "            trial_spikes = spike_times[(spike_times >= trial_start) & (spike_times <= trial_stop)]\n",
    "            trial_firing_rate = len(trial_spikes) / trial_duration if trial_duration > 0 else 0\n",
    "            failure_rates[unit_idx].append(trial_firing_rate)\n",
    "    \n",
    "    # Calculate average rates\n",
    "    avg_success_rates = {unit_idx: np.mean(rates) for unit_idx, rates in success_rates.items() if rates}\n",
    "    avg_failure_rates = {unit_idx: np.mean(rates) for unit_idx, rates in failure_rates.items() if rates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654d6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for visualization\n",
    "if 'success' in trial_df.columns:\n",
    "    outcome_data = []\n",
    "    for unit_idx in analysis_unit_indices:\n",
    "        unit_name = units[\"unit_name\"].data[unit_idx]\n",
    "        success_rate = avg_success_rates.get(unit_idx, 0)\n",
    "        failure_rate = avg_failure_rates.get(unit_idx, 0)\n",
    "        \n",
    "        outcome_data.append({\n",
    "            'Unit': f\"Unit {unit_name}\",\n",
    "            'Outcome': 'Success',\n",
    "            'Firing Rate (Hz)': success_rate\n",
    "        })\n",
    "        outcome_data.append({\n",
    "            'Unit': f\"Unit {unit_name}\",\n",
    "            'Outcome': 'Failure',\n",
    "            'Firing Rate (Hz)': failure_rate\n",
    "        })\n",
    "    \n",
    "    outcome_df = pd.DataFrame(outcome_data)\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(data=outcome_df, x='Unit', y='Firing Rate (Hz)', hue='Outcome', palette=['#2ecc71', '#e74c3c'])\n",
    "    plt.title('Neural Activity by Trial Outcome', fontsize=16)\n",
    "    plt.xlabel('', fontsize=14)\n",
    "    plt.ylabel('Average Firing Rate (Hz)', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(title='', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65461160",
   "metadata": {},
   "source": [
    "## Electrode Information\n",
    "\n",
    "Let's examine the electrode information to understand the recording setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc25bf2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Get electrode information\n",
    "electrodes = nwb.ec_electrodes\n",
    "print(f\"Number of electrodes: {len(electrodes['id'].data[:])}\")\n",
    "print(f\"Electrode properties: {electrodes.colnames}\")\n",
    "\n",
    "# Get electrode locations\n",
    "locations = electrodes[\"location\"].data[:]\n",
    "location_counts = {}\n",
    "for loc in locations:\n",
    "    if loc in location_counts:\n",
    "        location_counts[loc] += 1\n",
    "    else:\n",
    "        location_counts[loc] = 1\n",
    "\n",
    "print(f\"Electrode locations: {location_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fb547a",
   "metadata": {},
   "source": [
    "## Scientific Hypothesis Testing\n",
    "\n",
    "This dataset can be used to test various scientific hypotheses about neural coding in the posterior parietal cortex during mental navigation. Here's an example of how you might approach a hypothesis:\n",
    "\n",
    "**Hypothesis**: Neural activity in the PPC encodes navigation distance, with firing rates modulated by the distance between start and target positions.\n",
    "\n",
    "Let's test this by examining the relationship between firing rates and navigation distance across all trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e708c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a more comprehensive analysis that would test our hypothesis\n",
    "# We'll create a function to calculate firing rates for all good units across all trials\n",
    "\n",
    "def calculate_unit_rates_by_distance(unit_indices, trial_indices, distances):\n",
    "    \"\"\"Calculate firing rates for units across trials grouped by distance\"\"\"\n",
    "    unit_rates_by_distance = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for trial_idx in trial_indices:\n",
    "        if not valid_indices[trial_idx]:\n",
    "            continue\n",
    "            \n",
    "        trial_start = start_times[trial_idx]\n",
    "        trial_stop = stop_times[trial_idx]\n",
    "        trial_duration = trial_stop - trial_start\n",
    "        \n",
    "        if trial_duration <= 0:\n",
    "            continue\n",
    "            \n",
    "        dist = distances[trial_idx]\n",
    "        \n",
    "        for unit_idx in unit_indices:\n",
    "            # Get spike times for this unit\n",
    "            spike_times = units[\"spike_times\"][unit_idx]\n",
    "            \n",
    "            # Count spikes during this trial\n",
    "            trial_spikes = spike_times[(spike_times >= trial_start) & (spike_times <= trial_stop)]\n",
    "            trial_firing_rate = len(trial_spikes) / trial_duration\n",
    "            \n",
    "            unit_rates_by_distance[unit_idx][dist].append(trial_firing_rate)\n",
    "    \n",
    "    return unit_rates_by_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed8ee45",
   "metadata": {},
   "source": [
    "For a full analysis, you would run the function above on all trials and analyze the results. However, this would be computationally intensive and time-consuming for this notebook. \n",
    "\n",
    "Based on our sample analysis, we observed that:\n",
    "\n",
    "1. Different units show different patterns of activity across navigation distances\n",
    "2. Some units appear to have higher firing rates during successful trials\n",
    "\n",
    "These observations suggest that PPC neurons may indeed encode aspects of the mental navigation task, but a more comprehensive analysis would be needed to fully test our hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b360fa",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored [DANDI:001275](https://neurosift.app/dandiset/001275), a dataset containing neural recordings from the posterior parietal cortex during a mental navigation task. We've examined:\n",
    "\n",
    "1. The task structure and behavioral performance\n",
    "2. Neural activity patterns during navigation\n",
    "3. Relationships between neural activity and task parameters\n",
    "\n",
    "Key findings:\n",
    "\n",
    "- Success rate decreases as navigation distance increases\n",
    "- Neural activity in the PPC appears to be modulated by task parameters\n",
    "- Different neurons show different patterns of activity during the task\n",
    "\n",
    "This dataset provides a valuable resource for studying the neural basis of mental navigation and spatial cognition in primates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff22db",
   "metadata": {},
   "source": [
    "## Further Exploration\n",
    "\n",
    "To further explore this dataset, you might:\n",
    "\n",
    "1. Analyze neural activity across different sessions and subjects\n",
    "2. Compare with the related entorhinal cortex dataset\n",
    "3. Apply more advanced analysis techniques such as population decoding or dimensionality reduction\n",
    "4. Correlate neural activity with specific behavioral events during navigation\n",
    "\n",
    "The full dataset contains many more NWB files with additional recordings that could be analyzed using similar approaches."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
