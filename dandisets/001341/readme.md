# 001341

Content in this directory should be generated by cline using the neurosift-tools MCP. The idea is that we want to be able to auto-generate introductory notebooks, etc, based on prompts. So the purpose here is to develop those prompts.

A user responsible for creating the content will instruct cline to "follow the instructions in @dandisets/001341/readme.md"

## Instructions for cline

If the neurosift-tools MCP is not installed, then the user should be prompted to install it.

For all generated notebooks, prominently inform the user that the notebook was AI-generated and has not been fully verified by humans, and that they should be cautious when interpreting the code or results.

You should make use of the tools in neurosift-tools to generate the content for this directory.

Create a notebook.py with "# %%" delimiters. This is an introduction to Dandiset 001341 with illustrative plots. Please include plenty of comments to describe the experiment and the data. The examples and plots should help the user get started in loading and processing the data.

You should use `# %% [markdown]` for markdown cells

If you load data from only select files, then you should indicate which files you are using.

Hint: it doesn't work to try to index an h5py.Dataset with a numpy array of indices.

If you are going to load a subset of data, it doesn't make sense to load all of the timestamps in memory and then select a subset. Instead, you should load the timestamps for the subset of data you are interested in. So we shouldn't ever see something like `dataset.timestamps[:]` unless we intend to load all the timestamps.

When loading data for illustration, be careful about the size of the data, since the files are hosted remotely and datasets are streamed over the network. You may want to load subsets of data. But if you do, please be sure to indicate that you are doing so, so the reader doesn't get the wrong impression about the data.

If you want to investigate some aspects of the data prior to making the notebook, you can write a temporary python script called something like scratch1.py and run it to see the output. This may give you information about the content of the data that you wouldn't have by just using the available tools. However, it's important that you use the nwb_file_info tool from neurosift-tools prior to trying to do anything with an NWB file.

Keep in mind that through your tool calls you have been given information about what data is available in the files, whereas the reader of the notebook does not have access to that information. So in your illustration it might be helpful to show how they could get that information (e.g., columns in a table, etc).

Do not worry about pynwb typing errors from the linter.

You can ask the user to try it out.

Once satisfied, you can convert to notebook.ipynb using `jupytext --to notebook notebook.py`

Finally, use nbconvert to run that notebook and fill in the output cells in place.

## Dandiset-specific information

IMPORTANT: There seems to be a problem in the trials table where the stop_time is incorrect. Instead of "start_time" and "stop_time", you should instead use the "file_start_time" and "file_stop_time" columns for now.

The trials data is relatively small, so you can load that into memory in its entirety. Figure out a nice way to show the trials data in the notebook. Maybe give an indication of the trials durations and/or the start and stop times.

For others time series data, you should just load the first 1000 timepoints or so. (Note: if we don't say this, the the AI tends to load all the timestamps in order to determine masks, etc.)

Show how to load the units data, and perhaps plot some quality metrics, spike trains, keeping aware to not download too much data.

Then you could try making a simple Peri-Stimulus Time Histogram (PSTH) plot.

When referring to units, use the unit ID rather than the unit index.

If you are going to display a raster plot, make sure the time window is long enought that you at least get some spikes.

It's nice to pick some quality metrics to highlight, but you should also show the user how to get a list of all the quality metrics available.
